{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "### Python classifier based on k-NNFP algorithm (k nearest neighbours on features projection)             ###\n",
    "#############################################################################################################\n",
    "#\n",
    "# The fit() function just stores training data as is\n",
    "# \n",
    "# The predict() function uses the k-nnfp algorithm to return the classes of the data passed as a parameter\n",
    "# by doing a majority voting for the classes found for each neighbour, according to each individual feature.\n",
    "#\n",
    "# In other words, it's like doing k-NN on each individual feature with a majority voting at the end\n",
    "# to determine the class.\n",
    "#\n",
    "# The classifier expects classes to be numbered from 0 to n.\n",
    "# \n",
    "# Furthermore, it expects that missing data be of type np.nan in order to avoid them correctly,\n",
    "# so you should convert your dataset accordingly (i.e. replace ? with np.nan for example)\n",
    "#\n",
    "#############################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Extract from http://nimbusvault.net/publications/koala/assr/papers/k17is-223.pdf :\n",
    "\n",
    "K-Nearest Neighbors on Feature Projections algorithm (k-NNFP):\n",
    "The K-Nearest Neighbors on Feature Projections (k-NNFP) algorithm is an alternative approach of the\n",
    "state-of-the-art k-NN classification process. This approach is based on extracted votes applied on a set of\n",
    "classes, which derive after k-NN performance in each feature separately of the unclassified example.\n",
    "The most important characteristic of this classification algorithm is that the training set is stored as an\n",
    "equivalent projection set on feature space. In the dataset that is delivered below in Table 1 three training\n",
    "examples with two features and a class feature per example is presented.\n",
    "\n",
    "----------------------------------\n",
    "Training Example  f0  f1  Class\n",
    "   Example 1      1   6     B\n",
    "   Example 2      4   3     A\n",
    "   Example 3     10   5     A\n",
    "----------------------------------\n",
    "Table 1. Training Examples\n",
    "----------------------------------\n",
    "\n",
    "The k-NNFP algorithm classifies a given unclassified examples as follows. Firstly,\n",
    "the k-closest training examples are calculated for each feature, and their classes\n",
    "are stored, separately. In the next step, the sum of each class is calculated in\n",
    "\n",
    "feature storage space. Finally, the class with the max sum is performed to be the\n",
    "class of the unclassified example.\n",
    "In example, given an unclassified example (<3, 2>), where f0 = 3, f1 = 2 and the\n",
    "label class is unknown, the k-NNFP approach classifies the example to the ‘A’\n",
    "class for k = 1 and k = 2, as it is presented in Table 2:\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "k   f0      f1     Features’ Bag   Class\n",
    "1  [A]      [A]      [A, A]          A\n",
    "2 [A, B]  [A, A]  [A, B, A, A]       A\n",
    "-----------------------------------------------------------------\n",
    "Table 2. K-NNFP classification for unclassified example (<3, 2>)\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Considering their differences and the similarities, the k-NN approach focuses on\n",
    "the distances between training dataset and unclassified examples that provide the\n",
    "outcome classification on feature space, in opposite with the k-NNFP approach,\n",
    "which is mainly focused on each feature contribution to the classification process\n",
    "via the majority of feature votes.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import numpy as np\n",
    "\n",
    "# Based on a sklearn default classifier template\n",
    "class kNNFPClassifier(ClassifierMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, n_neighbours=1):\n",
    "        self.n_neighbours = n_neighbours\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        # Commented because we do accept NaN values... they are handled later on in the code below\n",
    "        # Another possibility would be to impute missing values (mean, median, ...)\n",
    "        \n",
    "        #X, y = check_X_y(X, y) \n",
    "        \n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        # Commented because we do accept NaN values... they are handled later on in the code below\n",
    "        \n",
    "        #check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "        # Commented because we do accept NaN values... they are handled later on in the code below.\n",
    "        \n",
    "        #X = check_array(X) \n",
    "        \n",
    "        # Array containing the classes found at the end of the algorithm for every tested instance\n",
    "        # (every line of array passed in parameter)\n",
    "        found_class = np.zeros(X.shape[0])\n",
    "        # Iterating on all the lines of X (all the instances to be classified)\n",
    "        for instance_index in range(X.shape[0]) :\n",
    "            # To store the classes of the features for the n_neighbours neighbours\n",
    "            neigbours_features_classes = np.zeros((self.n_neighbours, X.shape[1]))\n",
    "            # Iterating on X transposed, so on the columns (features) of the train data\n",
    "            for column in range(len(self.X_.T)) :\n",
    "                # Initialize the array of the already found neighbours with -1 values\n",
    "                # (no neighbours at the moment)\n",
    "                already_found_neighbours_rows = [-1]*self.n_neighbours\n",
    "                # We want to find n_neighbours neighbours\n",
    "                for neighbour_index in range(self.n_neighbours) :\n",
    "                    # For every new neighbours we seek, we initialize the closest value at the max possible\n",
    "                    # distance (max possible value for a float64) : every new neighbours found has to be\n",
    "                    # closer than that.\n",
    "                    closest = np.finfo(np.float64).max\n",
    "                    # Iterating on all the train data to look for neighbours\n",
    "                    for row in range(len(self.X_)) :\n",
    "                        # We only check for lines which have not already been picked as neighbours\n",
    "                        if row not in already_found_neighbours_rows :\n",
    "                            # We are only testing the distances if the data exist (not NaN)\n",
    "                            if (np.isnan(X[instance_index][column]) == False) & (np.isnan(self.X_[row][column]) == False) :\n",
    "                                # Computes the distance between the current feature from X and the feature of\n",
    "                                # the train data of the current iteration\n",
    "                                distance = abs(X[instance_index][column] - self.X_[row][column])\n",
    "                                # If we find a closer one... \n",
    "                                if distance < closest :\n",
    "                                    # ...we store its value as the closest known\n",
    "                                    closest = distance\n",
    "                                    # Store the class of this new closest\n",
    "                                    neigbours_features_classes[neighbour_index][column] = self.y_[row]\n",
    "                                    # Mark the row of this new neighbour as already selected\n",
    "                                    # (we don't want to parse it again in next iterations)\n",
    "                                    already_found_neighbours_rows[neighbour_index] = row\n",
    "            # Flatten the class array in order to apply majority voting\n",
    "            neigbours_features_classes = neigbours_features_classes.flatten()\n",
    "            # Cast as a numpy array for majority voting\n",
    "            neigbours_features_classes = np.array(neigbours_features_classes).astype(int)\n",
    "            # Counting the bins of every class\n",
    "            counts = np.bincount(neigbours_features_classes)\n",
    "            # Majority voting to determine the class\n",
    "            found_class[instance_index] = np.argmax(counts)\n",
    "\n",
    "        return found_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.85714286 0.9047619  0.95238095 0.85714286 1.        ]\n",
      "Accuracy: 0.9142857142857143 +/- 0.05553287518900288*2\n"
     ]
    }
   ],
   "source": [
    "# Test on Iris dataset\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "irisdata = iris.data\n",
    "irisclasses = iris.target\n",
    "\n",
    "# Create train and test datasets to evaluate generalization performance of the model\n",
    "# No need to stratify here because the dataset is balanced (50 samples for each of the 3 classes)\n",
    "# random_state fixed (9) for reproductibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(irisdata, irisclasses, test_size=0.3, shuffle=True, random_state=9)\n",
    "\n",
    "knnfp_classifier = kNNFPClassifier(15)\n",
    "knnfp_classifier.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knnfp_classifier, X_train, y_train, cv=5)\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = knnfp_classifier.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.95238095 0.9047619  0.95238095 0.85714286 1.        ]\n",
      "Accuracy: 0.9333333333333332 +/- 0.04856209060564558*2\n",
      "MAE: 0.022222222222222223\n"
     ]
    }
   ],
   "source": [
    "### Comparison with classic k-NN algorithm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### k-NNFP seems to work slightly better on test set. Restults are rather similar however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/micmac/anaconda3/envs/keras/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting ucimlrepo\n",
      "  Obtaining dependency information for ucimlrepo from https://files.pythonhosted.org/packages/85/8b/aab8a1c1344af158feb0b7f13d15ae184bc1e93625cea98d9c783b2e29d4/ucimlrepo-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading ucimlrepo-0.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading ucimlrepo-0.0.2-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.96551724 1.         0.96428571 0.96428571 0.96428571]\n",
      "Accuracy: 0.9716748768472907 +/- 0.01417059099866258*2\n",
      "MAE: 0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "### Test on the Wine dataset (UCI) : predict the origin country of wines basing on their chemical composition\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch dataset \n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# Data (as pandas dataframes) \n",
    "X = wine.data.features \n",
    "y = wine.data.targets \n",
    "\n",
    "X = X.to_numpy()\n",
    "X = np.array(X).astype(float)\n",
    "y = y.to_numpy()\n",
    "y = np.array(y).astype(int)\n",
    "y = y.ravel() #Converts the classes in scikit-learn format (1d list)\n",
    "\n",
    "# Changes the range of classes to be 0 to n (instead of 1 to n)\n",
    "y = y - np.array([1]*y.shape[0])\n",
    "\n",
    "# Random shuffling to avoid a (possible) pre-existing ordering in the data\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=9)\n",
    "\n",
    "# Create train and test datasets to evaluate generalization performance of the model\n",
    "# Doing stratify here because of imbalanced dataset\n",
    "# random_state fixed (9) for reproductibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=9)\n",
    "\n",
    "knnfp_classifier = kNNFPClassifier(5)\n",
    "knnfp_classifier.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knnfp_classifier, X_train, y_train, cv=5)\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")\n",
    "\n",
    "y_pred = knnfp_classifier.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.68965517 0.68965517 0.75       0.57142857 0.67857143]\n",
      "Accuracy: 0.6758620689655173 +/- 0.05794933694325902*2\n",
      "MAE: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "### Comparison with classic k-NN algorithm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### On this dataset, k-NNFP works much better than k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Test on the Dermatology dataset (UCI) : skin disease diagnostic (classification)\n",
    "import pandas as pd\n",
    "\n",
    "col_list = [*range(0,34,1)]\n",
    "data_frame = pd.read_csv(\"./datasets/DermatologyDataset/dermatology.data\", sep=\",\", header=None, usecols=col_list, encoding ='latin1')\n",
    "\n",
    "col_list = [34]\n",
    "classes = pd.read_csv(\"./datasets/DermatologyDataset/dermatology.data\", sep=\",\", header=None, usecols=col_list, encoding ='latin1')\n",
    "\n",
    "# Replace missing values with np.nan (which our classifier handles)\n",
    "data_frame.replace('?',np.nan, inplace=True)\n",
    "\n",
    "# Converts the dataframe into a numpy array, and stores the classes in a separate np array\n",
    "dermato_data = data_frame.to_numpy()\n",
    "dermato_data = np.array(dermato_data).astype(float)\n",
    "dermato_classes = classes.to_numpy()\n",
    "dermato_classes = np.array(dermato_classes).astype(int)\n",
    "dermato_classes = dermato_classes.ravel() #met les classes sous la forme demandée par scikit-learn (liste 1d)\n",
    "\n",
    "# Changes the range of classes to be 0 to n (instead of 1 to n)\n",
    "dermato_classes = dermato_classes - np.array([1]*dermato_classes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.15254237 0.49152542 0.48275862 0.44827586 0.44827586]\n",
      "Accuracy: 0.40467562828755116 +/- 0.12728941819646267*2\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets to evaluate generalization performance of the model\n",
    "# Doing stratify here because of imbalanced dataset\n",
    "# random_state fixed (9) for reproductibility\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Random shuffling to avoid a (possible) pre-existing ordering in the data\n",
    "from sklearn.utils import shuffle\n",
    "dermato_data, dermato_classes = shuffle(dermato_data, dermato_classes, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dermato_data, dermato_classes, stratify=dermato_classes, test_size=0.2)\n",
    "\n",
    "knnfp_classifier = kNNFPClassifier(5)\n",
    "knnfp_classifier.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knnfp_classifier, X_train, y_train, cv=5)\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7972972972972973\n"
     ]
    }
   ],
   "source": [
    "y_pred = knnfp_classifier.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.83050847 0.86440678 0.96551724 0.86206897 0.87931034]\n",
      "Accuracy: 0.8803623611922852 +/- 0.04544689049020901*2\n"
     ]
    }
   ],
   "source": [
    "### Comparing with classical k-NN algorithm\n",
    "### Imputing missing data by the mean\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X_train)\n",
    "X_train_imputed = imp.transform(X_train)\n",
    "imp.fit(X_test)\n",
    "X_test_imputed = imp.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_imputed, y_train)\n",
    "\n",
    "scores = cross_val_score(knn, X_train_imputed, y_train, cv=5)\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5405405405405406\n",
      "test accuracy: 0.7702702702702703\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test_imputed)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"test accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Bad results for k-NNFP on this dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test on the Arrythmia dataset (UCI)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "col_list = [*range(0,279,1)]\n",
    "data_frame = pd.read_csv(\"./datasets/ArrhythmiaDataset/arrhythmia.data\", sep=\",\", header=None, usecols=col_list, encoding ='latin1')\n",
    "\n",
    "col_list = [279]\n",
    "classes = pd.read_csv(\"./datasets/ArrhythmiaDataset/arrhythmia.data\", sep=\",\", header=None, usecols=col_list, encoding ='latin1')\n",
    "\n",
    "# Replace missing values with np.nan (which our classifier handles)\n",
    "data_frame.replace('?',np.nan, inplace=True)\n",
    "\n",
    "# Converts the dataframe into a numpy array, and stores the classes in a separate np array\n",
    "arrythm_data = data_frame.to_numpy()\n",
    "arrythm_data = np.array(arrythm_data).astype(float)\n",
    "arrythm_classes = classes.to_numpy()\n",
    "arrythm_classes = np.array(arrythm_classes).astype(int)\n",
    "arrythm_classes = arrythm_classes.ravel() #met les classes sous la forme demandée par scikit-learn (liste 1d)\n",
    "\n",
    "# Changes the range of classes to be 0 to n (instead of 1 to n)\n",
    "arrythm_classes = arrythm_classes - np.array([1]*arrythm_classes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/micmac/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.5625     0.57142857 0.55555556 0.55555556 0.55555556]\n",
      "Accuracy: 0.5601190476190476 +/- 0.006261799142087081*2\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets to evaluate generalization performance of the model\n",
    "# No need to stratify here because the dataset is balanced (50 samples for each of the 3 classes)\n",
    "# random_state fixed (9) for reproductibility\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Random shuffling to avoid a (possible) pre-existing ordering in the data\n",
    "arrythm_data, arrythm_classes = shuffle(arrythm_data, arrythm_classes, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(arrythm_data, arrythm_classes, test_size=0.3)\n",
    "\n",
    "knnfp_classifier = kNNFPClassifier(5)\n",
    "knnfp_classifier.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knnfp_classifier, X_train, y_train, cv=5)\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.1544117647058822\n",
      "test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_pred = knnfp_classifier.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"test accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Bad score on this dataset, but there are under-populated classes (1, 2, or 3 members)\n",
    "### and a majoritary class (more than 200 members)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Trying imputing missing data by the mean\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Random shuffling to avoid a (possible) pre-existing ordering in the data\n",
    "from sklearn.utils import shuffle\n",
    "arrythm_data, arrythm_classes = shuffle(arrythm_data, arrythm_classes, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(arrythm_data, arrythm_classes, test_size=0.3)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X_train)\n",
    "X_train_imputed = imp.transform(X_train)\n",
    "imp.fit(X_test)\n",
    "X_test_imputed = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/micmac/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores cross_val: [0.0625     0.55555556 0.55555556 0.55555556 0.55555556]\n",
      "Accuracy: 0.4569444444444445 +/- 0.19722222222222224*2\n"
     ]
    }
   ],
   "source": [
    "knnfp_classifier = kNNFPClassifier(5)\n",
    "knnfp_classifier.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knnfp_classifier, X_train_imputed, y_train, cv=5, error_score=\"raise\")\n",
    "print(f\"scores cross_val: {scores}\")\n",
    "print(f\"Accuracy: {scores.mean()} +/- {scores.std()}*2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.639705882352941\n",
      "test accuracy: 0.5147058823529411\n"
     ]
    }
   ],
   "source": [
    "y_pred = knnfp_classifier.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_pred)}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"test accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not much improvement with imputation either..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6253/260256341.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.jp-Cell { width: 80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
